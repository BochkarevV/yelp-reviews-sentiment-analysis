# YELP Reviews Sentiment Analysis

## Task
In this project, we learn and compare several Transformers-based models. 
The task we are solving is known as sentiment analysis. In a nutshell, 
the models learn to classify free text reviews as positive and negative ones.

## Data
We use YELP reviews for this task. Original Yelp Open Dataset is available 
[here](https://www.yelp.com/dataset).

To reduce the training time and avoid using expensive and often 
unavailable hardware, we extract 25,000 records per star rating (125,000 
reviews in total) and split them into training, validation and test sets 
for development and final model evaluation. This is still too much for 
ordinary CPUs to process in a reasonable time. Fortunately, Google Colab
with various up to 16GB GPUs comes in handy here and allows to train the
models in an acceptable time. 

Basic exploratory data analysis of the subsample is available in 
`notebooks/yelp_eda.ipynb`. 

## Repository Structure
* `data` - contains the data we're using for development and testing purposes. 
Since both initial dataset and the subsample are quite large, this folder will
need to be created locally. We only need `yelp_academic_dataset_review.json.zip`
from the [original dataset](https://www.yelp.com/dataset) to be stored in `data`.
Subsample of the dataset can be generated by running `utils.dataset_utils.py`.   
* `models` - model, training, evaluation and prediction definitions.
* `notebooks` - auxiliary notebooks, such as data exploration and example of 
the model usage.
* `utils` - helpers and supplementary methods, such as subsampling original dataset 
and text preprocessing for subsequent transformers models training.
* `.gitignore` - lists files and folders ignored by git.
* `main.py` - default root of the project, not used at the moment.
* `README.md` - the doc you're reading :)
* `requirements.txt` - project dependencies. Run `pip install -r requirements.txt`

## Model
