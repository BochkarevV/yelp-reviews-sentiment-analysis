{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "yelp_reviews_sentiment_analysis.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "HZnIU6r0KsNc",
    "colab_type": "text"
   },
   "source": [
    "# YELP Reviews Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlLGfs1J5cbC",
    "colab_type": "text"
   },
   "source": [
    "In this notebook, we'll fine-tune transformers to handle sentiment analysis task on YELP reviews. More specifically, we will classify reviews into two categories: positive and negative. Short basic explorative data analysis notebook is available in `notebooks/yelp_eda.ipynb`.\n",
    "\n",
    "We'll use HuggingFace `transformers` to build a model. It's definition and training process are encapsulated into a separate class called `TransformersGeneric`. Additionally, some convenience utilities are defined in `utils` module, e.g. training/validation/test set splitting and text preprocessing routines.\n",
    "\n",
    "We'll track the training process with Weights & Biases and all runs along with their metrics will be available here: https://app.wandb.ai/vasily/yelp-reviews-sentiment-analysis?workspace=user-vasily\n",
    "\n",
    "Transformer-based models training is barely feasible on CPU due to millions of trainable parameters, thus it's recommended to use GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XtUtfZgKsNd",
    "colab_type": "text"
   },
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy6GBG4A8_9T",
    "colab_type": "text"
   },
   "source": [
    "First, install and import the libraries used throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AeoEJPCpLU0i",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%pip install -qq transformers\n",
    "%pip install -qq wandb"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4WhcxVUQKsNe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AlbertForSequenceClassification      # Can change to Bert..., Roberta..., etc.\n",
    "from transformers import AlbertTokenizer                      # Can change to Bert..., Roberta..., etc.\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from utils.data_loading import load_and_split_dataset\n",
    "from utils.data_loading import data_loader_from_tensors\n",
    "from utils.text_preprocessing import TextPreprocessor\n",
    "\n",
    "from models.transformers_generic import TransformersGeneric\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGBhafirlK6c",
    "colab_type": "text"
   },
   "source": [
    "## WandB Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbjhRBI59t5Z",
    "colab_type": "text"
   },
   "source": [
    "Set up WandB tracking."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5KqAYJMXlJ7D",
    "colab_type": "code",
    "outputId": "82866208-2f9e-42ae-90c5-dfc5c18c6c2c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590967253611,
     "user_tz": -120,
     "elapsed": 5751,
     "user": {
      "displayName": "Vasily Bochkarev",
      "photoUrl": "",
      "userId": "16683603869006222688"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIs4tnD19yeU",
    "colab_type": "text"
   },
   "source": [
    "Define the project and hyperparameters of the run. It is also important to make sure that `model_name` fits the model architecture imported previously and trained in the next steps. For a list model architectures and associated `model_name`s refer to https://huggingface.co/transformers/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F6BqT0wquBnC",
    "colab_type": "code",
    "outputId": "c9487f74-e502-4380-b349-e27593c13e78",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590967256162,
     "user_tz": -120,
     "elapsed": 3153,
     "user": {
      "displayName": "Vasily Bochkarev",
      "photoUrl": "",
      "userId": "16683603869006222688"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    }
   },
   "source": [
    "config = {\n",
    "  'model_name': 'albert-base-v2',\n",
    "  'learning_rate': 2e-5,\n",
    "  'epochs': 4\n",
    "}\n",
    "\n",
    "wandb.init(project='yelp-reviews-sentiment-analysis', magic=True, config=config)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/vasily/yelp-reviews-sentiment-analysis\" target=\"_blank\">https://app.wandb.ai/vasily/yelp-reviews-sentiment-analysis</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/vasily/yelp-reviews-sentiment-analysis/runs/3fy9wmwp\" target=\"_blank\">https://app.wandb.ai/vasily/yelp-reviews-sentiment-analysis/runs/3fy9wmwp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/vasily/yelp-reviews-sentiment-analysis/runs/3fy9wmwp"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHGLDXrIKsNh",
    "colab_type": "text"
   },
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP43MhDX9635",
    "colab_type": "text"
   },
   "source": [
    "YELP dataset contains huge reviews corpus which is impossible to use with big and resource-demanding transformer models on a standard PC or laptop. Thus, we have previously extracted a subsample of the data used in this project. It contains 125,000 reviews which we'll use for training (60%), validation (20%) and testing(20%)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fXGJ8p0lKsNi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Load the dataset, data/yelp_reviews.json.gz by default.\n",
    "# Use 60% of the data for training, 20% for validation and 20% for testing purposes.\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = load_and_split_dataset('../data/yelp_reviews.json.gz')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBhrfuRf_HZv",
    "colab_type": "text"
   },
   "source": [
    "We'll define 4- and 5-stars as positive and the rest as negative reviews. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NnJfQokB4Q3W",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 1, 2 or 3 stars - negative\n",
    "# 4 or 5 stars - positive\n",
    "y_train_sent = torch.tensor(list(map(lambda x: int(x > 3), y_train)))\n",
    "y_val_sent = torch.tensor(list(map(lambda x: int(x > 3), y_val)))\n",
    "y_test_sent = torch.tensor(list(map(lambda x: int(x > 3), y_test)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bahR9z23_gSF",
    "colab_type": "text"
   },
   "source": [
    "Text preprocessing includes tokenization and padding/truncating of the input sequences to the same length. In addition, we are creating data loaders for further use in training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "XkireHEeKsNl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Prepare the data for Transformers\n",
    "preprocessor = TextPreprocessor(tokenizer=AlbertTokenizer, vocab_file=wandb.config.model_name)\n",
    "train_tensor, train_masks_tensor = preprocessor.preprocess(X_train, fit=True)\n",
    "val_tensor, val_masks_tensor = preprocessor.preprocess(X_val)\n",
    "test_tensor, test_masks_tensor = preprocessor.preprocess(X_test)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5fKr9IRUKsNp",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Create data loaders\n",
    "train_data_loader = data_loader_from_tensors(train_tensor, train_masks_tensor, y_train_sent, batch_size=16)\n",
    "val_data_loader = data_loader_from_tensors(val_tensor, val_masks_tensor, y_val_sent, batch_size=16)\n",
    "test_data_loader = data_loader_from_tensors(test_tensor, test_masks_tensor, y_test_sent, batch_size=16)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36KvoqAMKsNs",
    "colab_type": "text"
   },
   "source": [
    "## Model Creation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMrw3kumAMdp",
    "colab_type": "text"
   },
   "source": [
    "`TransformersGeneric` class accept several parameters (see docstring), however, there are three more important ones:\n",
    "\n",
    "1. `num_classes` - number of classes in the task. In case of sentiment analysis we have only two classes.\n",
    "2. `transformers_model` - **classification** model architecture from `transformers` library.\n",
    "3. `model_name` - pre-defined model name available in `transformers`. Full list is available here (shortcut name): https://huggingface.co/transformers/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_5RsfVRTKsNs",
    "colab_type": "code",
    "outputId": "84b95621-9d34-46b7-e0c7-219db3bc712e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590967360944,
     "user_tz": -120,
     "elapsed": 99346,
     "user": {
      "displayName": "Vasily Bochkarev",
      "photoUrl": "",
      "userId": "16683603869006222688"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "source": [
    "# Initialize a model\n",
    "generic = TransformersGeneric(num_classes=2, \n",
    "                              transformers_model=AlbertForSequenceClassification,\n",
    "                              model_name=wandb.config.model_name)\n",
    "\n",
    "wandb.watch(generic.model, log='all')"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Tesla P100-PCIE-16GB is used...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f830730e828>]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJeZCGRtBXiB",
    "colab_type": "text"
   },
   "source": [
    "Next, we set up an optimizer and a scheduler. We'll use Adam with weight decay and linearly schedule learning rate to decrease over time without warmup. We follow the recommendation in the original [BERT paper](https://arxiv.org/abs/1810.04805) and use 4 epochs for training and learning rate equal to `2e-5`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MVHWiI1fKsNv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Define optimizer\n",
    "optimizer = AdamW(generic.get_parameters(), lr=wandb.config.learning_rate, eps=1e-8)\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs\n",
    "total_steps = len(train_data_loader) * wandb.config.epochs\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8o-DABs5Cbso",
    "colab_type": "text"
   },
   "source": [
    "Train the model and store the training metrics in a variable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OchNrWH0KsNy",
    "colab_type": "code",
    "outputId": "ee8e8313-4689-40c2-ffe9-230c2aeb8402",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590985807313,
     "user_tz": -120,
     "elapsed": 18446358,
     "user": {
      "displayName": "Vasily Bochkarev",
      "photoUrl": "",
      "userId": "16683603869006222688"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "train_metrics = generic.train(train_data_loader, val_data_loader, optimizer, scheduler, wandb.config.epochs)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------\t1\t-------------------------\n",
      "Training...\n",
      "\tBatch 25/4688, elapsed 00:00:21.32\n",
      "\tBatch 50/4688, elapsed 00:00:43.19\n",
      "\tBatch 75/4688, elapsed 00:01:05.08\n",
      "\tBatch 100/4688, elapsed 00:01:26.95\n",
      "\tBatch 125/4688, elapsed 00:01:49.21\n",
      "\tBatch 150/4688, elapsed 00:02:11.06\n",
      "\tBatch 175/4688, elapsed 00:02:32.95\n",
      "\tBatch 200/4688, elapsed 00:02:54.82\n",
      "\tBatch 225/4688, elapsed 00:03:17.08\n",
      "\tBatch 250/4688, elapsed 00:03:38.97\n",
      "\tBatch 275/4688, elapsed 00:04:00.84\n",
      "\tBatch 300/4688, elapsed 00:04:22.74\n",
      "\tBatch 325/4688, elapsed 00:04:45.00\n",
      "\tBatch 350/4688, elapsed 00:05:06.87\n",
      "\tBatch 375/4688, elapsed 00:05:28.76\n",
      "\tBatch 400/4688, elapsed 00:05:50.62\n",
      "\tBatch 425/4688, elapsed 00:06:12.88\n",
      "\tBatch 450/4688, elapsed 00:06:34.77\n",
      "\tBatch 475/4688, elapsed 00:06:56.64\n",
      "\tBatch 500/4688, elapsed 00:07:18.53\n",
      "\tBatch 525/4688, elapsed 00:07:40.79\n",
      "\tBatch 550/4688, elapsed 00:08:02.72\n",
      "\tBatch 575/4688, elapsed 00:08:24.62\n",
      "\tBatch 600/4688, elapsed 00:08:46.52\n",
      "\tBatch 625/4688, elapsed 00:09:08.80\n",
      "\tBatch 650/4688, elapsed 00:09:30.71\n",
      "\tBatch 675/4688, elapsed 00:09:52.60\n",
      "\tBatch 700/4688, elapsed 00:10:14.50\n",
      "\tBatch 725/4688, elapsed 00:10:36.79\n",
      "\tBatch 750/4688, elapsed 00:10:58.72\n",
      "\tBatch 775/4688, elapsed 00:11:20.63\n",
      "\tBatch 800/4688, elapsed 00:11:42.58\n",
      "\tBatch 825/4688, elapsed 00:12:04.86\n",
      "\tBatch 850/4688, elapsed 00:12:26.77\n",
      "\tBatch 875/4688, elapsed 00:12:48.69\n",
      "\tBatch 900/4688, elapsed 00:13:10.57\n",
      "\tBatch 925/4688, elapsed 00:13:32.85\n",
      "\tBatch 950/4688, elapsed 00:13:54.75\n",
      "\tBatch 975/4688, elapsed 00:14:16.64\n",
      "\tBatch 1000/4688, elapsed 00:14:38.55\n",
      "\tBatch 1025/4688, elapsed 00:15:00.84\n",
      "\tBatch 1050/4688, elapsed 00:15:22.73\n",
      "\tBatch 1075/4688, elapsed 00:15:44.65\n",
      "\tBatch 1100/4688, elapsed 00:16:06.55\n",
      "\tBatch 1125/4688, elapsed 00:16:28.82\n",
      "\tBatch 1150/4688, elapsed 00:16:50.73\n",
      "\tBatch 1175/4688, elapsed 00:17:12.63\n",
      "\tBatch 1200/4688, elapsed 00:17:34.52\n",
      "\tBatch 1225/4688, elapsed 00:17:56.82\n",
      "\tBatch 1250/4688, elapsed 00:18:18.74\n",
      "\tBatch 1275/4688, elapsed 00:18:40.66\n",
      "\tBatch 1300/4688, elapsed 00:19:02.58\n",
      "\tBatch 1325/4688, elapsed 00:19:24.86\n",
      "\tBatch 1350/4688, elapsed 00:19:46.79\n",
      "\tBatch 1375/4688, elapsed 00:20:08.69\n",
      "\tBatch 1400/4688, elapsed 00:20:30.59\n",
      "\tBatch 1425/4688, elapsed 00:20:52.88\n",
      "\tBatch 1450/4688, elapsed 00:21:14.78\n",
      "\tBatch 1475/4688, elapsed 00:21:36.68\n",
      "\tBatch 1500/4688, elapsed 00:21:58.61\n",
      "\tBatch 1525/4688, elapsed 00:22:20.88\n",
      "\tBatch 1550/4688, elapsed 00:22:42.81\n",
      "\tBatch 1575/4688, elapsed 00:23:04.70\n",
      "\tBatch 1600/4688, elapsed 00:23:26.62\n",
      "\tBatch 1625/4688, elapsed 00:23:48.88\n",
      "\tBatch 1650/4688, elapsed 00:24:10.77\n",
      "\tBatch 1675/4688, elapsed 00:24:32.68\n",
      "\tBatch 1700/4688, elapsed 00:24:54.59\n",
      "\tBatch 1725/4688, elapsed 00:25:16.88\n",
      "\tBatch 1750/4688, elapsed 00:25:38.81\n",
      "\tBatch 1775/4688, elapsed 00:26:00.72\n",
      "\tBatch 1800/4688, elapsed 00:26:22.62\n",
      "\tBatch 1825/4688, elapsed 00:26:44.90\n",
      "\tBatch 1850/4688, elapsed 00:27:06.81\n",
      "\tBatch 1875/4688, elapsed 00:27:28.70\n",
      "\tBatch 1900/4688, elapsed 00:27:50.61\n",
      "\tBatch 1925/4688, elapsed 00:28:12.91\n",
      "\tBatch 1950/4688, elapsed 00:28:34.81\n",
      "\tBatch 1975/4688, elapsed 00:28:56.71\n",
      "\tBatch 2000/4688, elapsed 00:29:18.60\n",
      "\tBatch 2025/4688, elapsed 00:29:40.90\n",
      "\tBatch 2050/4688, elapsed 00:30:02.79\n",
      "\tBatch 2075/4688, elapsed 00:30:24.71\n",
      "\tBatch 2100/4688, elapsed 00:30:46.62\n",
      "\tBatch 2125/4688, elapsed 00:31:08.89\n",
      "\tBatch 2150/4688, elapsed 00:31:30.78\n",
      "\tBatch 2175/4688, elapsed 00:31:52.70\n",
      "\tBatch 2200/4688, elapsed 00:32:14.60\n",
      "\tBatch 2225/4688, elapsed 00:32:36.89\n",
      "\tBatch 2250/4688, elapsed 00:32:58.79\n",
      "\tBatch 2275/4688, elapsed 00:33:20.69\n",
      "\tBatch 2300/4688, elapsed 00:33:42.60\n",
      "\tBatch 2325/4688, elapsed 00:34:04.88\n",
      "\tBatch 2350/4688, elapsed 00:34:26.79\n",
      "\tBatch 2375/4688, elapsed 00:34:48.68\n",
      "\tBatch 2400/4688, elapsed 00:35:10.59\n",
      "\tBatch 2425/4688, elapsed 00:35:32.88\n",
      "\tBatch 2450/4688, elapsed 00:35:54.80\n",
      "\tBatch 2475/4688, elapsed 00:36:16.70\n",
      "\tBatch 2500/4688, elapsed 00:36:38.60\n",
      "\tBatch 2525/4688, elapsed 00:37:00.89\n",
      "\tBatch 2550/4688, elapsed 00:37:22.81\n",
      "\tBatch 2575/4688, elapsed 00:37:44.72\n",
      "\tBatch 2600/4688, elapsed 00:38:06.64\n",
      "\tBatch 2625/4688, elapsed 00:38:28.91\n",
      "\tBatch 2650/4688, elapsed 00:38:50.83\n",
      "\tBatch 2675/4688, elapsed 00:39:12.73\n",
      "\tBatch 2700/4688, elapsed 00:39:34.64\n",
      "\tBatch 2725/4688, elapsed 00:39:56.93\n",
      "\tBatch 2750/4688, elapsed 00:40:18.86\n",
      "\tBatch 2775/4688, elapsed 00:40:40.78\n",
      "\tBatch 2800/4688, elapsed 00:41:02.69\n",
      "\tBatch 2825/4688, elapsed 00:41:25.00\n",
      "\tBatch 2850/4688, elapsed 00:41:46.92\n",
      "\tBatch 2875/4688, elapsed 00:42:08.82\n",
      "\tBatch 2900/4688, elapsed 00:42:30.74\n",
      "\tBatch 2925/4688, elapsed 00:42:53.06\n",
      "\tBatch 2950/4688, elapsed 00:43:14.99\n",
      "\tBatch 2975/4688, elapsed 00:43:36.91\n",
      "\tBatch 3000/4688, elapsed 00:43:58.87\n",
      "\tBatch 3025/4688, elapsed 00:44:21.15\n",
      "\tBatch 3050/4688, elapsed 00:44:43.08\n",
      "\tBatch 3075/4688, elapsed 00:45:05.02\n",
      "\tBatch 3100/4688, elapsed 00:45:26.97\n",
      "\tBatch 3125/4688, elapsed 00:45:49.26\n",
      "\tBatch 3150/4688, elapsed 00:46:11.19\n",
      "\tBatch 3175/4688, elapsed 00:46:33.12\n",
      "\tBatch 3200/4688, elapsed 00:46:55.05\n",
      "\tBatch 3225/4688, elapsed 00:47:17.37\n",
      "\tBatch 3250/4688, elapsed 00:47:39.32\n",
      "\tBatch 3275/4688, elapsed 00:48:01.26\n",
      "\tBatch 3300/4688, elapsed 00:48:23.19\n",
      "\tBatch 3325/4688, elapsed 00:48:45.50\n",
      "\tBatch 3350/4688, elapsed 00:49:07.41\n",
      "\tBatch 3375/4688, elapsed 00:49:29.36\n",
      "\tBatch 3400/4688, elapsed 00:49:51.30\n",
      "\tBatch 3425/4688, elapsed 00:50:13.61\n",
      "\tBatch 3450/4688, elapsed 00:50:35.57\n",
      "\tBatch 3475/4688, elapsed 00:50:57.49\n",
      "\tBatch 3500/4688, elapsed 00:51:19.45\n",
      "\tBatch 3525/4688, elapsed 00:51:41.74\n",
      "\tBatch 3550/4688, elapsed 00:52:03.69\n",
      "\tBatch 3575/4688, elapsed 00:52:25.62\n",
      "\tBatch 3600/4688, elapsed 00:52:47.55\n",
      "\tBatch 3625/4688, elapsed 00:53:09.88\n",
      "\tBatch 3650/4688, elapsed 00:53:31.83\n",
      "\tBatch 3675/4688, elapsed 00:53:53.75\n",
      "\tBatch 3700/4688, elapsed 00:54:15.69\n",
      "\tBatch 3725/4688, elapsed 00:54:37.98\n",
      "\tBatch 3750/4688, elapsed 00:54:59.94\n",
      "\tBatch 3775/4688, elapsed 00:55:21.88\n",
      "\tBatch 3800/4688, elapsed 00:55:43.83\n",
      "\tBatch 3825/4688, elapsed 00:56:06.14\n",
      "\tBatch 3850/4688, elapsed 00:56:28.10\n",
      "\tBatch 3875/4688, elapsed 00:56:50.03\n",
      "\tBatch 3900/4688, elapsed 00:57:11.96\n",
      "\tBatch 3925/4688, elapsed 00:57:34.28\n",
      "\tBatch 3950/4688, elapsed 00:57:56.20\n",
      "\tBatch 3975/4688, elapsed 00:58:18.13\n",
      "\tBatch 4000/4688, elapsed 00:58:40.05\n",
      "\tBatch 4025/4688, elapsed 00:59:02.39\n",
      "\tBatch 4050/4688, elapsed 00:59:24.34\n",
      "\tBatch 4075/4688, elapsed 00:59:46.28\n",
      "\tBatch 4100/4688, elapsed 01:00:08.20\n",
      "\tBatch 4125/4688, elapsed 01:00:30.53\n",
      "\tBatch 4150/4688, elapsed 01:00:52.46\n",
      "\tBatch 4175/4688, elapsed 01:01:14.42\n",
      "\tBatch 4200/4688, elapsed 01:01:36.37\n",
      "\tBatch 4225/4688, elapsed 01:01:58.67\n",
      "\tBatch 4250/4688, elapsed 01:02:20.62\n",
      "\tBatch 4275/4688, elapsed 01:02:42.55\n",
      "\tBatch 4300/4688, elapsed 01:03:04.50\n",
      "\tBatch 4325/4688, elapsed 01:03:26.81\n",
      "\tBatch 4350/4688, elapsed 01:03:48.76\n",
      "\tBatch 4375/4688, elapsed 01:04:10.69\n",
      "\tBatch 4400/4688, elapsed 01:04:32.63\n",
      "\tBatch 4425/4688, elapsed 01:04:54.95\n",
      "\tBatch 4450/4688, elapsed 01:05:16.88\n",
      "\tBatch 4475/4688, elapsed 01:05:38.80\n",
      "\tBatch 4500/4688, elapsed 01:06:00.73\n",
      "\tBatch 4525/4688, elapsed 01:06:23.03\n",
      "\tBatch 4550/4688, elapsed 01:06:44.97\n",
      "\tBatch 4575/4688, elapsed 01:07:06.90\n",
      "\tBatch 4600/4688, elapsed 01:07:28.83\n",
      "\tBatch 4625/4688, elapsed 01:07:51.16\n",
      "\tBatch 4650/4688, elapsed 01:08:13.09\n",
      "\tBatch 4675/4688, elapsed 01:08:35.03\n",
      "\n",
      "\tAverage training loss: 0.01673149958475109\n",
      "\tTraining epoch time: 01:08:46.90\n",
      "\n",
      "Validating...\n",
      "\tAverage validation loss: 0.015453557978635648\n",
      "\tF1: 0.9011516314779271\n",
      "\tAccuracy: 0.9011516314779271\n",
      "\tValidation time: 00:08:00.37\n",
      "\n",
      "-------------------------\t2\t-------------------------\n",
      "Training...\n",
      "\tBatch 25/4688, elapsed 00:00:21.10\n",
      "\tBatch 50/4688, elapsed 00:00:43.37\n",
      "\tBatch 75/4688, elapsed 00:01:05.31\n",
      "\tBatch 100/4688, elapsed 00:01:27.24\n",
      "\tBatch 125/4688, elapsed 00:01:49.21\n",
      "\tBatch 150/4688, elapsed 00:02:11.47\n",
      "\tBatch 175/4688, elapsed 00:02:33.42\n",
      "\tBatch 200/4688, elapsed 00:02:55.35\n",
      "\tBatch 225/4688, elapsed 00:03:17.34\n",
      "\tBatch 250/4688, elapsed 00:03:39.61\n",
      "\tBatch 275/4688, elapsed 00:04:01.56\n",
      "\tBatch 300/4688, elapsed 00:04:23.52\n",
      "\tBatch 325/4688, elapsed 00:04:45.54\n",
      "\tBatch 350/4688, elapsed 00:05:07.84\n",
      "\tBatch 375/4688, elapsed 00:05:29.79\n",
      "\tBatch 400/4688, elapsed 00:05:51.73\n",
      "\tBatch 425/4688, elapsed 00:06:13.73\n",
      "\tBatch 450/4688, elapsed 00:06:36.01\n",
      "\tBatch 475/4688, elapsed 00:06:57.96\n",
      "\tBatch 500/4688, elapsed 00:07:19.91\n",
      "\tBatch 525/4688, elapsed 00:07:41.91\n",
      "\tBatch 550/4688, elapsed 00:08:04.18\n",
      "\tBatch 575/4688, elapsed 00:08:26.12\n",
      "\tBatch 600/4688, elapsed 00:08:48.06\n",
      "\tBatch 625/4688, elapsed 00:09:10.05\n",
      "\tBatch 650/4688, elapsed 00:09:32.33\n",
      "\tBatch 675/4688, elapsed 00:09:54.29\n",
      "\tBatch 700/4688, elapsed 00:10:16.24\n",
      "\tBatch 725/4688, elapsed 00:10:38.24\n",
      "\tBatch 750/4688, elapsed 00:11:00.51\n",
      "\tBatch 775/4688, elapsed 00:11:22.43\n",
      "\tBatch 800/4688, elapsed 00:11:44.36\n",
      "\tBatch 825/4688, elapsed 00:12:06.35\n",
      "\tBatch 850/4688, elapsed 00:12:28.60\n",
      "\tBatch 875/4688, elapsed 00:12:50.54\n",
      "\tBatch 900/4688, elapsed 00:13:12.48\n",
      "\tBatch 925/4688, elapsed 00:13:34.48\n",
      "\tBatch 950/4688, elapsed 00:13:56.75\n",
      "\tBatch 975/4688, elapsed 00:14:18.67\n",
      "\tBatch 1000/4688, elapsed 00:14:40.61\n",
      "\tBatch 1025/4688, elapsed 00:15:02.61\n",
      "\tBatch 1050/4688, elapsed 00:15:24.88\n",
      "\tBatch 1075/4688, elapsed 00:15:46.83\n",
      "\tBatch 1100/4688, elapsed 00:16:08.77\n",
      "\tBatch 1125/4688, elapsed 00:16:30.75\n",
      "\tBatch 1150/4688, elapsed 00:16:53.02\n",
      "\tBatch 1175/4688, elapsed 00:17:14.94\n",
      "\tBatch 1200/4688, elapsed 00:17:36.89\n",
      "\tBatch 1225/4688, elapsed 00:17:58.87\n",
      "\tBatch 1250/4688, elapsed 00:18:21.14\n",
      "\tBatch 1275/4688, elapsed 00:18:43.08\n",
      "\tBatch 1300/4688, elapsed 00:19:05.01\n",
      "\tBatch 1325/4688, elapsed 00:19:27.00\n",
      "\tBatch 1350/4688, elapsed 00:19:49.26\n",
      "\tBatch 1375/4688, elapsed 00:20:11.19\n",
      "\tBatch 1400/4688, elapsed 00:20:33.12\n",
      "\tBatch 1425/4688, elapsed 00:20:55.12\n",
      "\tBatch 1450/4688, elapsed 00:21:17.37\n",
      "\tBatch 1475/4688, elapsed 00:21:39.31\n",
      "\tBatch 1500/4688, elapsed 00:22:01.25\n",
      "\tBatch 1525/4688, elapsed 00:22:23.23\n",
      "\tBatch 1550/4688, elapsed 00:22:45.50\n",
      "\tBatch 1575/4688, elapsed 00:23:07.44\n",
      "\tBatch 1600/4688, elapsed 00:23:29.37\n",
      "\tBatch 1625/4688, elapsed 00:23:51.36\n",
      "\tBatch 1650/4688, elapsed 00:24:13.64\n",
      "\tBatch 1675/4688, elapsed 00:24:35.58\n",
      "\tBatch 1700/4688, elapsed 00:24:57.53\n",
      "\tBatch 1725/4688, elapsed 00:25:19.52\n",
      "\tBatch 1750/4688, elapsed 00:25:41.77\n",
      "\tBatch 1775/4688, elapsed 00:26:03.72\n",
      "\tBatch 1800/4688, elapsed 00:26:25.66\n",
      "\tBatch 1825/4688, elapsed 00:26:47.63\n",
      "\tBatch 1850/4688, elapsed 00:27:09.89\n",
      "\tBatch 1875/4688, elapsed 00:27:31.83\n",
      "\tBatch 1900/4688, elapsed 00:27:53.75\n",
      "\tBatch 1925/4688, elapsed 00:28:15.74\n",
      "\tBatch 1950/4688, elapsed 00:28:38.00\n",
      "\tBatch 1975/4688, elapsed 00:28:59.93\n",
      "\tBatch 2000/4688, elapsed 00:29:21.86\n",
      "\tBatch 2025/4688, elapsed 00:29:43.84\n",
      "\tBatch 2050/4688, elapsed 00:30:06.11\n",
      "\tBatch 2075/4688, elapsed 00:30:28.04\n",
      "\tBatch 2100/4688, elapsed 00:30:49.96\n",
      "\tBatch 2125/4688, elapsed 00:31:11.95\n",
      "\tBatch 2150/4688, elapsed 00:31:34.23\n",
      "\tBatch 2175/4688, elapsed 00:31:56.16\n",
      "\tBatch 2200/4688, elapsed 00:32:18.10\n",
      "\tBatch 2225/4688, elapsed 00:32:40.07\n",
      "\tBatch 2250/4688, elapsed 00:33:02.34\n",
      "\tBatch 2275/4688, elapsed 00:33:24.26\n",
      "\tBatch 2300/4688, elapsed 00:33:46.19\n",
      "\tBatch 2325/4688, elapsed 00:34:08.18\n",
      "\tBatch 2350/4688, elapsed 00:34:30.43\n",
      "\tBatch 2375/4688, elapsed 00:34:52.37\n",
      "\tBatch 2400/4688, elapsed 00:35:14.30\n",
      "\tBatch 2425/4688, elapsed 00:35:36.27\n",
      "\tBatch 2450/4688, elapsed 00:35:58.54\n",
      "\tBatch 2475/4688, elapsed 00:36:20.50\n",
      "\tBatch 2500/4688, elapsed 00:36:42.46\n",
      "\tBatch 2525/4688, elapsed 00:37:04.45\n",
      "\tBatch 2550/4688, elapsed 00:37:26.70\n",
      "\tBatch 2575/4688, elapsed 00:37:48.62\n",
      "\tBatch 2600/4688, elapsed 00:38:10.56\n",
      "\tBatch 2625/4688, elapsed 00:38:32.53\n",
      "\tBatch 2650/4688, elapsed 00:38:54.78\n",
      "\tBatch 2675/4688, elapsed 00:39:16.72\n",
      "\tBatch 2700/4688, elapsed 00:39:38.65\n",
      "\tBatch 2725/4688, elapsed 00:40:00.62\n",
      "\tBatch 2750/4688, elapsed 00:40:22.88\n",
      "\tBatch 2775/4688, elapsed 00:40:44.82\n",
      "\tBatch 2800/4688, elapsed 00:41:06.76\n",
      "\tBatch 2825/4688, elapsed 00:41:28.74\n",
      "\tBatch 2850/4688, elapsed 00:41:51.00\n",
      "\tBatch 2875/4688, elapsed 00:42:12.94\n",
      "\tBatch 2900/4688, elapsed 00:42:34.87\n",
      "\tBatch 2925/4688, elapsed 00:42:56.85\n",
      "\tBatch 2950/4688, elapsed 00:43:19.08\n",
      "\tBatch 2975/4688, elapsed 00:43:41.00\n",
      "\tBatch 3000/4688, elapsed 00:44:02.93\n",
      "\tBatch 3025/4688, elapsed 00:44:24.90\n",
      "\tBatch 3050/4688, elapsed 00:44:47.15\n",
      "\tBatch 3075/4688, elapsed 00:45:09.06\n",
      "\tBatch 3100/4688, elapsed 00:45:30.98\n",
      "\tBatch 3125/4688, elapsed 00:45:52.96\n",
      "\tBatch 3150/4688, elapsed 00:46:15.21\n",
      "\tBatch 3175/4688, elapsed 00:46:37.14\n",
      "\tBatch 3200/4688, elapsed 00:46:59.07\n",
      "\tBatch 3225/4688, elapsed 00:47:21.03\n",
      "\tBatch 3250/4688, elapsed 00:47:43.29\n",
      "\tBatch 3275/4688, elapsed 00:48:05.21\n",
      "\tBatch 3300/4688, elapsed 00:48:27.13\n",
      "\tBatch 3325/4688, elapsed 00:48:49.09\n",
      "\tBatch 3350/4688, elapsed 00:49:11.35\n",
      "\tBatch 3375/4688, elapsed 00:49:33.28\n",
      "\tBatch 3400/4688, elapsed 00:49:55.21\n",
      "\tBatch 3425/4688, elapsed 00:50:17.18\n",
      "\tBatch 3450/4688, elapsed 00:50:39.43\n",
      "\tBatch 3475/4688, elapsed 00:51:01.36\n",
      "\tBatch 3500/4688, elapsed 00:51:23.29\n",
      "\tBatch 3525/4688, elapsed 00:51:45.27\n",
      "\tBatch 3550/4688, elapsed 00:52:07.53\n",
      "\tBatch 3575/4688, elapsed 00:52:29.47\n",
      "\tBatch 3600/4688, elapsed 00:52:51.39\n",
      "\tBatch 3625/4688, elapsed 00:53:13.36\n",
      "\tBatch 3650/4688, elapsed 00:53:35.62\n",
      "\tBatch 3675/4688, elapsed 00:53:57.55\n",
      "\tBatch 3700/4688, elapsed 00:54:19.48\n",
      "\tBatch 3725/4688, elapsed 00:54:41.45\n",
      "\tBatch 3750/4688, elapsed 00:55:03.70\n",
      "\tBatch 3775/4688, elapsed 00:55:25.61\n",
      "\tBatch 3800/4688, elapsed 00:55:47.53\n",
      "\tBatch 3825/4688, elapsed 00:56:09.49\n",
      "\tBatch 3850/4688, elapsed 00:56:31.75\n",
      "\tBatch 3875/4688, elapsed 00:56:53.67\n",
      "\tBatch 3900/4688, elapsed 00:57:15.61\n",
      "\tBatch 3925/4688, elapsed 00:57:37.58\n",
      "\tBatch 3950/4688, elapsed 00:57:59.82\n",
      "\tBatch 3975/4688, elapsed 00:58:21.73\n",
      "\tBatch 4000/4688, elapsed 00:58:43.66\n",
      "\tBatch 4025/4688, elapsed 00:59:05.64\n",
      "\tBatch 4050/4688, elapsed 00:59:27.92\n",
      "\tBatch 4075/4688, elapsed 00:59:49.85\n",
      "\tBatch 4100/4688, elapsed 01:00:11.78\n",
      "\tBatch 4125/4688, elapsed 01:00:33.75\n",
      "\tBatch 4150/4688, elapsed 01:00:56.01\n",
      "\tBatch 4175/4688, elapsed 01:01:17.96\n",
      "\tBatch 4200/4688, elapsed 01:01:39.89\n",
      "\tBatch 4225/4688, elapsed 01:02:01.87\n",
      "\tBatch 4250/4688, elapsed 01:02:24.15\n",
      "\tBatch 4275/4688, elapsed 01:02:46.07\n",
      "\tBatch 4300/4688, elapsed 01:03:08.01\n",
      "\tBatch 4325/4688, elapsed 01:03:29.99\n",
      "\tBatch 4350/4688, elapsed 01:03:52.23\n",
      "\tBatch 4375/4688, elapsed 01:04:14.16\n",
      "\tBatch 4400/4688, elapsed 01:04:36.09\n",
      "\tBatch 4425/4688, elapsed 01:04:58.06\n",
      "\tBatch 4450/4688, elapsed 01:05:20.32\n",
      "\tBatch 4475/4688, elapsed 01:05:42.22\n",
      "\tBatch 4500/4688, elapsed 01:06:04.15\n",
      "\tBatch 4525/4688, elapsed 01:06:26.13\n",
      "\tBatch 4550/4688, elapsed 01:06:48.38\n",
      "\tBatch 4575/4688, elapsed 01:07:10.29\n",
      "\tBatch 4600/4688, elapsed 01:07:32.23\n",
      "\tBatch 4625/4688, elapsed 01:07:54.21\n",
      "\tBatch 4650/4688, elapsed 01:08:16.46\n",
      "\tBatch 4675/4688, elapsed 01:08:38.40\n",
      "\n",
      "\tAverage training loss: 0.012979380023188344\n",
      "\tTraining epoch time: 01:08:50.25\n",
      "\n",
      "Validating...\n",
      "\tAverage validation loss: 0.01393527731758805\n",
      "\tF1: 0.91302783109405\n",
      "\tAccuracy: 0.91302783109405\n",
      "\tValidation time: 00:08:00.29\n",
      "\n",
      "-------------------------\t3\t-------------------------\n",
      "Training...\n",
      "\tBatch 25/4688, elapsed 00:00:21.11\n",
      "\tBatch 50/4688, elapsed 00:00:43.04\n",
      "\tBatch 75/4688, elapsed 00:01:04.99\n",
      "\tBatch 100/4688, elapsed 00:01:27.25\n",
      "\tBatch 125/4688, elapsed 00:01:49.22\n",
      "\tBatch 150/4688, elapsed 00:02:11.16\n",
      "\tBatch 175/4688, elapsed 00:02:33.09\n",
      "\tBatch 200/4688, elapsed 00:02:55.34\n",
      "\tBatch 225/4688, elapsed 00:03:17.32\n",
      "\tBatch 250/4688, elapsed 00:03:39.26\n",
      "\tBatch 275/4688, elapsed 00:04:01.20\n",
      "\tBatch 300/4688, elapsed 00:04:23.47\n",
      "\tBatch 325/4688, elapsed 00:04:45.47\n",
      "\tBatch 350/4688, elapsed 00:05:07.41\n",
      "\tBatch 375/4688, elapsed 00:05:29.36\n",
      "\tBatch 400/4688, elapsed 00:05:51.63\n",
      "\tBatch 425/4688, elapsed 00:06:13.62\n",
      "\tBatch 450/4688, elapsed 00:06:35.57\n",
      "\tBatch 475/4688, elapsed 00:06:57.50\n",
      "\tBatch 500/4688, elapsed 00:07:19.79\n",
      "\tBatch 525/4688, elapsed 00:07:41.79\n",
      "\tBatch 550/4688, elapsed 00:08:03.73\n",
      "\tBatch 575/4688, elapsed 00:08:25.67\n",
      "\tBatch 600/4688, elapsed 00:08:47.90\n",
      "\tBatch 625/4688, elapsed 00:09:09.87\n",
      "\tBatch 650/4688, elapsed 00:09:31.82\n",
      "\tBatch 675/4688, elapsed 00:09:53.76\n",
      "\tBatch 700/4688, elapsed 00:10:16.02\n",
      "\tBatch 725/4688, elapsed 00:10:38.00\n",
      "\tBatch 750/4688, elapsed 00:10:59.95\n",
      "\tBatch 775/4688, elapsed 00:11:21.90\n",
      "\tBatch 800/4688, elapsed 00:11:44.18\n",
      "\tBatch 825/4688, elapsed 00:12:06.17\n",
      "\tBatch 850/4688, elapsed 00:12:28.12\n",
      "\tBatch 875/4688, elapsed 00:12:50.06\n",
      "\tBatch 900/4688, elapsed 00:13:12.31\n",
      "\tBatch 925/4688, elapsed 00:13:34.30\n",
      "\tBatch 950/4688, elapsed 00:13:56.24\n",
      "\tBatch 975/4688, elapsed 00:14:18.19\n",
      "\tBatch 1000/4688, elapsed 00:14:40.44\n",
      "\tBatch 1025/4688, elapsed 00:15:02.43\n",
      "\tBatch 1050/4688, elapsed 00:15:24.36\n",
      "\tBatch 1075/4688, elapsed 00:15:46.31\n",
      "\tBatch 1100/4688, elapsed 00:16:08.58\n",
      "\tBatch 1125/4688, elapsed 00:16:30.57\n",
      "\tBatch 1150/4688, elapsed 00:16:52.50\n",
      "\tBatch 1175/4688, elapsed 00:17:14.45\n",
      "\tBatch 1200/4688, elapsed 00:17:36.72\n",
      "\tBatch 1225/4688, elapsed 00:17:58.71\n",
      "\tBatch 1250/4688, elapsed 00:18:20.65\n",
      "\tBatch 1275/4688, elapsed 00:18:42.60\n",
      "\tBatch 1300/4688, elapsed 00:19:04.86\n",
      "\tBatch 1325/4688, elapsed 00:19:26.86\n",
      "\tBatch 1350/4688, elapsed 00:19:48.79\n",
      "\tBatch 1375/4688, elapsed 00:20:10.72\n",
      "\tBatch 1400/4688, elapsed 00:20:32.99\n",
      "\tBatch 1425/4688, elapsed 00:20:54.96\n",
      "\tBatch 1450/4688, elapsed 00:21:16.90\n",
      "\tBatch 1475/4688, elapsed 00:21:38.83\n",
      "\tBatch 1500/4688, elapsed 00:22:01.13\n",
      "\tBatch 1525/4688, elapsed 00:22:23.09\n",
      "\tBatch 1550/4688, elapsed 00:22:45.02\n",
      "\tBatch 1575/4688, elapsed 00:23:06.96\n",
      "\tBatch 1600/4688, elapsed 00:23:29.23\n",
      "\tBatch 1625/4688, elapsed 00:23:51.20\n",
      "\tBatch 1650/4688, elapsed 00:24:13.13\n",
      "\tBatch 1675/4688, elapsed 00:24:35.07\n",
      "\tBatch 1700/4688, elapsed 00:24:57.33\n",
      "\tBatch 1725/4688, elapsed 00:25:19.32\n",
      "\tBatch 1750/4688, elapsed 00:25:41.25\n",
      "\tBatch 1775/4688, elapsed 00:26:03.19\n",
      "\tBatch 1800/4688, elapsed 00:26:25.47\n",
      "\tBatch 1825/4688, elapsed 00:26:47.45\n",
      "\tBatch 1850/4688, elapsed 00:27:09.40\n",
      "\tBatch 1875/4688, elapsed 00:27:31.35\n",
      "\tBatch 1900/4688, elapsed 00:27:53.63\n",
      "\tBatch 1925/4688, elapsed 00:28:15.61\n",
      "\tBatch 1950/4688, elapsed 00:28:37.53\n",
      "\tBatch 1975/4688, elapsed 00:28:59.47\n",
      "\tBatch 2000/4688, elapsed 00:29:21.76\n",
      "\tBatch 2025/4688, elapsed 00:29:43.72\n",
      "\tBatch 2050/4688, elapsed 00:30:05.65\n",
      "\tBatch 2075/4688, elapsed 00:30:27.59\n",
      "\tBatch 2100/4688, elapsed 00:30:49.85\n",
      "\tBatch 2125/4688, elapsed 00:31:11.84\n",
      "\tBatch 2150/4688, elapsed 00:31:33.77\n",
      "\tBatch 2175/4688, elapsed 00:31:55.70\n",
      "\tBatch 2200/4688, elapsed 00:32:17.96\n",
      "\tBatch 2225/4688, elapsed 00:32:39.94\n",
      "\tBatch 2250/4688, elapsed 00:33:01.87\n",
      "\tBatch 2275/4688, elapsed 00:33:23.80\n",
      "\tBatch 2300/4688, elapsed 00:33:46.07\n",
      "\tBatch 2325/4688, elapsed 00:34:08.03\n",
      "\tBatch 2350/4688, elapsed 00:34:29.97\n",
      "\tBatch 2375/4688, elapsed 00:34:51.88\n",
      "\tBatch 2400/4688, elapsed 00:35:14.15\n",
      "\tBatch 2425/4688, elapsed 00:35:36.12\n",
      "\tBatch 2450/4688, elapsed 00:35:58.08\n",
      "\tBatch 2475/4688, elapsed 00:36:20.00\n",
      "\tBatch 2500/4688, elapsed 00:36:42.26\n",
      "\tBatch 2525/4688, elapsed 00:37:04.23\n",
      "\tBatch 2550/4688, elapsed 00:37:26.16\n",
      "\tBatch 2575/4688, elapsed 00:37:48.08\n",
      "\tBatch 2600/4688, elapsed 00:38:10.35\n",
      "\tBatch 2625/4688, elapsed 00:38:32.31\n",
      "\tBatch 2650/4688, elapsed 00:38:54.23\n",
      "\tBatch 2675/4688, elapsed 00:39:16.17\n",
      "\tBatch 2700/4688, elapsed 00:39:38.48\n",
      "\tBatch 2725/4688, elapsed 00:40:00.49\n",
      "\tBatch 2750/4688, elapsed 00:40:22.43\n",
      "\tBatch 2775/4688, elapsed 00:40:44.39\n",
      "\tBatch 2800/4688, elapsed 00:41:06.69\n",
      "\tBatch 2825/4688, elapsed 00:41:28.68\n",
      "\tBatch 2850/4688, elapsed 00:41:50.62\n",
      "\tBatch 2875/4688, elapsed 00:42:12.55\n",
      "\tBatch 2900/4688, elapsed 00:42:34.85\n",
      "\tBatch 2925/4688, elapsed 00:42:56.84\n",
      "\tBatch 2950/4688, elapsed 00:43:18.78\n",
      "\tBatch 2975/4688, elapsed 00:43:40.72\n",
      "\tBatch 3000/4688, elapsed 00:44:02.99\n",
      "\tBatch 3025/4688, elapsed 00:44:24.97\n",
      "\tBatch 3050/4688, elapsed 00:44:46.91\n",
      "\tBatch 3075/4688, elapsed 00:45:08.85\n",
      "\tBatch 3100/4688, elapsed 00:45:31.12\n",
      "\tBatch 3125/4688, elapsed 00:45:53.13\n",
      "\tBatch 3150/4688, elapsed 00:46:15.07\n",
      "\tBatch 3175/4688, elapsed 00:46:37.02\n",
      "\tBatch 3200/4688, elapsed 00:46:59.32\n",
      "\tBatch 3225/4688, elapsed 00:47:21.32\n",
      "\tBatch 3250/4688, elapsed 00:47:43.26\n",
      "\tBatch 3275/4688, elapsed 00:48:05.19\n",
      "\tBatch 3300/4688, elapsed 00:48:27.46\n",
      "\tBatch 3325/4688, elapsed 00:48:49.45\n",
      "\tBatch 3350/4688, elapsed 00:49:11.39\n",
      "\tBatch 3375/4688, elapsed 00:49:33.34\n",
      "\tBatch 3400/4688, elapsed 00:49:55.63\n",
      "\tBatch 3425/4688, elapsed 00:50:17.62\n",
      "\tBatch 3450/4688, elapsed 00:50:39.54\n",
      "\tBatch 3475/4688, elapsed 00:51:01.48\n",
      "\tBatch 3500/4688, elapsed 00:51:23.75\n",
      "\tBatch 3525/4688, elapsed 00:51:45.74\n",
      "\tBatch 3550/4688, elapsed 00:52:07.68\n",
      "\tBatch 3575/4688, elapsed 00:52:29.62\n",
      "\tBatch 3600/4688, elapsed 00:52:51.90\n",
      "\tBatch 3625/4688, elapsed 00:53:13.88\n",
      "\tBatch 3650/4688, elapsed 00:53:35.82\n",
      "\tBatch 3675/4688, elapsed 00:53:57.76\n",
      "\tBatch 3700/4688, elapsed 00:54:20.04\n",
      "\tBatch 3725/4688, elapsed 00:54:42.03\n",
      "\tBatch 3750/4688, elapsed 00:55:03.97\n",
      "\tBatch 3775/4688, elapsed 00:55:25.92\n",
      "\tBatch 3800/4688, elapsed 00:55:48.21\n",
      "\tBatch 3825/4688, elapsed 00:56:10.21\n",
      "\tBatch 3850/4688, elapsed 00:56:32.15\n",
      "\tBatch 3875/4688, elapsed 00:56:54.09\n",
      "\tBatch 3900/4688, elapsed 00:57:16.36\n",
      "\tBatch 3925/4688, elapsed 00:57:38.34\n",
      "\tBatch 3950/4688, elapsed 00:58:00.29\n",
      "\tBatch 3975/4688, elapsed 00:58:22.22\n",
      "\tBatch 4000/4688, elapsed 00:58:44.52\n",
      "\tBatch 4025/4688, elapsed 00:59:06.51\n",
      "\tBatch 4050/4688, elapsed 00:59:28.45\n",
      "\tBatch 4075/4688, elapsed 00:59:50.38\n",
      "\tBatch 4100/4688, elapsed 01:00:12.66\n",
      "\tBatch 4125/4688, elapsed 01:00:34.64\n",
      "\tBatch 4150/4688, elapsed 01:00:56.56\n",
      "\tBatch 4175/4688, elapsed 01:01:18.50\n",
      "\tBatch 4200/4688, elapsed 01:01:40.78\n",
      "\tBatch 4225/4688, elapsed 01:02:02.75\n",
      "\tBatch 4250/4688, elapsed 01:02:24.68\n",
      "\tBatch 4275/4688, elapsed 01:02:46.61\n",
      "\tBatch 4300/4688, elapsed 01:03:08.88\n",
      "\tBatch 4325/4688, elapsed 01:03:30.86\n",
      "\tBatch 4350/4688, elapsed 01:03:52.80\n",
      "\tBatch 4375/4688, elapsed 01:04:14.74\n",
      "\tBatch 4400/4688, elapsed 01:04:37.02\n",
      "\tBatch 4425/4688, elapsed 01:04:59.01\n",
      "\tBatch 4450/4688, elapsed 01:05:20.95\n",
      "\tBatch 4475/4688, elapsed 01:05:42.87\n",
      "\tBatch 4500/4688, elapsed 01:06:05.16\n",
      "\tBatch 4525/4688, elapsed 01:06:27.13\n",
      "\tBatch 4550/4688, elapsed 01:06:49.08\n",
      "\tBatch 4575/4688, elapsed 01:07:10.99\n",
      "\tBatch 4600/4688, elapsed 01:07:33.28\n",
      "\tBatch 4625/4688, elapsed 01:07:55.25\n",
      "\tBatch 4650/4688, elapsed 01:08:17.17\n",
      "\tBatch 4675/4688, elapsed 01:08:39.11\n",
      "\n",
      "\tAverage training loss: 0.01060645099887831\n",
      "\tTraining epoch time: 01:08:50.97\n",
      "\n",
      "Validating...\n",
      "\tAverage validation loss: 0.02462809686961638\n",
      "\tF1: 0.9084692898272553\n",
      "\tAccuracy: 0.9084692898272553\n",
      "\tValidation time: 00:08:01.43\n",
      "\n",
      "-------------------------\t4\t-------------------------\n",
      "Training...\n",
      "\tBatch 25/4688, elapsed 00:00:21.08\n",
      "\tBatch 50/4688, elapsed 00:00:43.40\n",
      "\tBatch 75/4688, elapsed 00:01:05.33\n",
      "\tBatch 100/4688, elapsed 00:01:27.26\n",
      "\tBatch 125/4688, elapsed 00:01:49.21\n",
      "\tBatch 150/4688, elapsed 00:02:11.55\n",
      "\tBatch 175/4688, elapsed 00:02:33.51\n",
      "\tBatch 200/4688, elapsed 00:02:55.45\n",
      "\tBatch 225/4688, elapsed 00:03:17.39\n",
      "\tBatch 250/4688, elapsed 00:03:39.69\n",
      "\tBatch 275/4688, elapsed 00:04:01.63\n",
      "\tBatch 300/4688, elapsed 00:04:23.57\n",
      "\tBatch 325/4688, elapsed 00:04:45.52\n",
      "\tBatch 350/4688, elapsed 00:05:07.84\n",
      "\tBatch 375/4688, elapsed 00:05:29.76\n",
      "\tBatch 400/4688, elapsed 00:05:51.70\n",
      "\tBatch 425/4688, elapsed 00:06:13.63\n",
      "\tBatch 450/4688, elapsed 00:06:35.98\n",
      "\tBatch 475/4688, elapsed 00:06:57.92\n",
      "\tBatch 500/4688, elapsed 00:07:19.85\n",
      "\tBatch 525/4688, elapsed 00:07:41.79\n",
      "\tBatch 550/4688, elapsed 00:08:04.13\n",
      "\tBatch 575/4688, elapsed 00:08:26.06\n",
      "\tBatch 600/4688, elapsed 00:08:47.98\n",
      "\tBatch 625/4688, elapsed 00:09:09.91\n",
      "\tBatch 650/4688, elapsed 00:09:32.26\n",
      "\tBatch 675/4688, elapsed 00:09:54.20\n",
      "\tBatch 700/4688, elapsed 00:10:16.15\n",
      "\tBatch 725/4688, elapsed 00:10:38.08\n",
      "\tBatch 750/4688, elapsed 00:11:00.42\n",
      "\tBatch 775/4688, elapsed 00:11:22.36\n",
      "\tBatch 800/4688, elapsed 00:11:44.30\n",
      "\tBatch 825/4688, elapsed 00:12:06.26\n",
      "\tBatch 850/4688, elapsed 00:12:28.60\n",
      "\tBatch 875/4688, elapsed 00:12:50.54\n",
      "\tBatch 900/4688, elapsed 00:13:12.48\n",
      "\tBatch 925/4688, elapsed 00:13:34.41\n",
      "\tBatch 950/4688, elapsed 00:13:56.71\n",
      "\tBatch 975/4688, elapsed 00:14:18.65\n",
      "\tBatch 1000/4688, elapsed 00:14:40.59\n",
      "\tBatch 1025/4688, elapsed 00:15:02.50\n",
      "\tBatch 1050/4688, elapsed 00:15:24.80\n",
      "\tBatch 1075/4688, elapsed 00:15:46.72\n",
      "\tBatch 1100/4688, elapsed 00:16:08.66\n",
      "\tBatch 1125/4688, elapsed 00:16:30.61\n",
      "\tBatch 1150/4688, elapsed 00:16:52.91\n",
      "\tBatch 1175/4688, elapsed 00:17:14.84\n",
      "\tBatch 1200/4688, elapsed 00:17:36.76\n",
      "\tBatch 1225/4688, elapsed 00:17:58.70\n",
      "\tBatch 1250/4688, elapsed 00:18:20.99\n",
      "\tBatch 1275/4688, elapsed 00:18:42.92\n",
      "\tBatch 1300/4688, elapsed 00:19:04.85\n",
      "\tBatch 1325/4688, elapsed 00:19:26.77\n",
      "\tBatch 1350/4688, elapsed 00:19:49.05\n",
      "\tBatch 1375/4688, elapsed 00:20:10.98\n",
      "\tBatch 1400/4688, elapsed 00:20:32.91\n",
      "\tBatch 1425/4688, elapsed 00:20:54.86\n",
      "\tBatch 1450/4688, elapsed 00:21:17.17\n",
      "\tBatch 1475/4688, elapsed 00:21:39.11\n",
      "\tBatch 1500/4688, elapsed 00:22:01.06\n",
      "\tBatch 1525/4688, elapsed 00:22:23.01\n",
      "\tBatch 1550/4688, elapsed 00:22:45.30\n",
      "\tBatch 1575/4688, elapsed 00:23:07.23\n",
      "\tBatch 1600/4688, elapsed 00:23:29.17\n",
      "\tBatch 1625/4688, elapsed 00:23:51.09\n",
      "\tBatch 1650/4688, elapsed 00:24:13.40\n",
      "\tBatch 1675/4688, elapsed 00:24:35.33\n",
      "\tBatch 1700/4688, elapsed 00:24:57.27\n",
      "\tBatch 1725/4688, elapsed 00:25:19.20\n",
      "\tBatch 1750/4688, elapsed 00:25:41.49\n",
      "\tBatch 1775/4688, elapsed 00:26:03.41\n",
      "\tBatch 1800/4688, elapsed 00:26:25.34\n",
      "\tBatch 1825/4688, elapsed 00:26:47.28\n",
      "\tBatch 1850/4688, elapsed 00:27:09.60\n",
      "\tBatch 1875/4688, elapsed 00:27:31.55\n",
      "\tBatch 1900/4688, elapsed 00:27:53.48\n",
      "\tBatch 1925/4688, elapsed 00:28:15.42\n",
      "\tBatch 1950/4688, elapsed 00:28:37.74\n",
      "\tBatch 1975/4688, elapsed 00:28:59.70\n",
      "\tBatch 2000/4688, elapsed 00:29:21.67\n",
      "\tBatch 2025/4688, elapsed 00:29:43.62\n",
      "\tBatch 2050/4688, elapsed 00:30:05.97\n",
      "\tBatch 2075/4688, elapsed 00:30:27.89\n",
      "\tBatch 2100/4688, elapsed 00:30:49.84\n",
      "\tBatch 2125/4688, elapsed 00:31:11.80\n",
      "\tBatch 2150/4688, elapsed 00:31:34.13\n",
      "\tBatch 2175/4688, elapsed 00:31:56.07\n",
      "\tBatch 2200/4688, elapsed 00:32:18.00\n",
      "\tBatch 2225/4688, elapsed 00:32:39.94\n",
      "\tBatch 2250/4688, elapsed 00:33:02.28\n",
      "\tBatch 2275/4688, elapsed 00:33:24.20\n",
      "\tBatch 2300/4688, elapsed 00:33:46.14\n",
      "\tBatch 2325/4688, elapsed 00:34:08.08\n",
      "\tBatch 2350/4688, elapsed 00:34:30.43\n",
      "\tBatch 2375/4688, elapsed 00:34:52.37\n",
      "\tBatch 2400/4688, elapsed 00:35:14.31\n",
      "\tBatch 2425/4688, elapsed 00:35:36.26\n",
      "\tBatch 2450/4688, elapsed 00:35:58.61\n",
      "\tBatch 2475/4688, elapsed 00:36:20.55\n",
      "\tBatch 2500/4688, elapsed 00:36:42.49\n",
      "\tBatch 2525/4688, elapsed 00:37:04.43\n",
      "\tBatch 2550/4688, elapsed 00:37:26.78\n",
      "\tBatch 2575/4688, elapsed 00:37:48.70\n",
      "\tBatch 2600/4688, elapsed 00:38:10.65\n",
      "\tBatch 2625/4688, elapsed 00:38:32.58\n",
      "\tBatch 2650/4688, elapsed 00:38:54.90\n",
      "\tBatch 2675/4688, elapsed 00:39:16.83\n",
      "\tBatch 2700/4688, elapsed 00:39:38.77\n",
      "\tBatch 2725/4688, elapsed 00:40:00.70\n",
      "\tBatch 2750/4688, elapsed 00:40:23.00\n",
      "\tBatch 2775/4688, elapsed 00:40:44.94\n",
      "\tBatch 2800/4688, elapsed 00:41:06.85\n",
      "\tBatch 2825/4688, elapsed 00:41:28.78\n",
      "\tBatch 2850/4688, elapsed 00:41:51.11\n",
      "\tBatch 2875/4688, elapsed 00:42:13.04\n",
      "\tBatch 2900/4688, elapsed 00:42:34.97\n",
      "\tBatch 2925/4688, elapsed 00:42:56.91\n",
      "\tBatch 2950/4688, elapsed 00:43:19.23\n",
      "\tBatch 2975/4688, elapsed 00:43:41.16\n",
      "\tBatch 3000/4688, elapsed 00:44:03.08\n",
      "\tBatch 3025/4688, elapsed 00:44:25.02\n",
      "\tBatch 3050/4688, elapsed 00:44:47.35\n",
      "\tBatch 3075/4688, elapsed 00:45:09.28\n",
      "\tBatch 3100/4688, elapsed 00:45:31.22\n",
      "\tBatch 3125/4688, elapsed 00:45:53.18\n",
      "\tBatch 3150/4688, elapsed 00:46:15.50\n",
      "\tBatch 3175/4688, elapsed 00:46:37.42\n",
      "\tBatch 3200/4688, elapsed 00:46:59.36\n",
      "\tBatch 3225/4688, elapsed 00:47:21.32\n",
      "\tBatch 3250/4688, elapsed 00:47:43.66\n",
      "\tBatch 3275/4688, elapsed 00:48:05.59\n",
      "\tBatch 3300/4688, elapsed 00:48:27.54\n",
      "\tBatch 3325/4688, elapsed 00:48:49.48\n",
      "\tBatch 3350/4688, elapsed 00:49:11.81\n",
      "\tBatch 3375/4688, elapsed 00:49:33.76\n",
      "\tBatch 3400/4688, elapsed 00:49:55.71\n",
      "\tBatch 3425/4688, elapsed 00:50:17.65\n",
      "\tBatch 3450/4688, elapsed 00:50:39.99\n",
      "\tBatch 3475/4688, elapsed 00:51:01.92\n",
      "\tBatch 3500/4688, elapsed 00:51:23.86\n",
      "\tBatch 3525/4688, elapsed 00:51:45.80\n",
      "\tBatch 3550/4688, elapsed 00:52:08.13\n",
      "\tBatch 3575/4688, elapsed 00:52:30.09\n",
      "\tBatch 3600/4688, elapsed 00:52:52.04\n",
      "\tBatch 3625/4688, elapsed 00:53:13.97\n",
      "\tBatch 3650/4688, elapsed 00:53:36.35\n",
      "\tBatch 3675/4688, elapsed 00:53:58.30\n",
      "\tBatch 3700/4688, elapsed 00:54:20.23\n",
      "\tBatch 3725/4688, elapsed 00:54:42.20\n",
      "\tBatch 3750/4688, elapsed 00:55:04.51\n",
      "\tBatch 3775/4688, elapsed 00:55:26.45\n",
      "\tBatch 3800/4688, elapsed 00:55:48.38\n",
      "\tBatch 3825/4688, elapsed 00:56:10.33\n",
      "\tBatch 3850/4688, elapsed 00:56:32.68\n",
      "\tBatch 3875/4688, elapsed 00:56:54.61\n",
      "\tBatch 3900/4688, elapsed 00:57:16.56\n",
      "\tBatch 3925/4688, elapsed 00:57:38.50\n",
      "\tBatch 3950/4688, elapsed 00:58:00.84\n",
      "\tBatch 3975/4688, elapsed 00:58:22.79\n",
      "\tBatch 4000/4688, elapsed 00:58:44.73\n",
      "\tBatch 4025/4688, elapsed 00:59:06.66\n",
      "\tBatch 4050/4688, elapsed 00:59:29.01\n",
      "\tBatch 4075/4688, elapsed 00:59:50.94\n",
      "\tBatch 4100/4688, elapsed 01:00:12.88\n",
      "\tBatch 4125/4688, elapsed 01:00:34.82\n",
      "\tBatch 4150/4688, elapsed 01:00:57.17\n",
      "\tBatch 4175/4688, elapsed 01:01:19.14\n",
      "\tBatch 4200/4688, elapsed 01:01:41.09\n",
      "\tBatch 4225/4688, elapsed 01:02:03.02\n",
      "\tBatch 4250/4688, elapsed 01:02:25.36\n",
      "\tBatch 4275/4688, elapsed 01:02:47.29\n",
      "\tBatch 4300/4688, elapsed 01:03:09.23\n",
      "\tBatch 4325/4688, elapsed 01:03:31.19\n",
      "\tBatch 4350/4688, elapsed 01:03:53.54\n",
      "\tBatch 4375/4688, elapsed 01:04:15.50\n",
      "\tBatch 4400/4688, elapsed 01:04:37.45\n",
      "\tBatch 4425/4688, elapsed 01:04:59.38\n",
      "\tBatch 4450/4688, elapsed 01:05:21.71\n",
      "\tBatch 4475/4688, elapsed 01:05:43.65\n",
      "\tBatch 4500/4688, elapsed 01:06:05.58\n",
      "\tBatch 4525/4688, elapsed 01:06:27.52\n",
      "\tBatch 4550/4688, elapsed 01:06:49.83\n",
      "\tBatch 4575/4688, elapsed 01:07:11.75\n",
      "\tBatch 4600/4688, elapsed 01:07:33.70\n",
      "\tBatch 4625/4688, elapsed 01:07:55.63\n",
      "\tBatch 4650/4688, elapsed 01:08:17.97\n",
      "\tBatch 4675/4688, elapsed 01:08:39.89\n",
      "\n",
      "\tAverage training loss: 0.006893584134903758\n",
      "\tTraining epoch time: 01:08:51.75\n",
      "\n",
      "Validating...\n",
      "\tAverage validation loss: 0.028901585380583097\n",
      "\tF1: 0.9102687140115163\n",
      "\tAccuracy: 0.9102687140115163\n",
      "\tValidation time: 00:08:01.44\n",
      "\n",
      "Training finished!\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfVbWwZtC4nH",
    "colab_type": "text"
   },
   "source": [
    "Log the metrics to WandB."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jRB7WEPQuooS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Log to WandB\n",
    "for metrics in train_metrics:\n",
    "  wandb.log(metrics)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPnBpMQzkJxV",
    "colab_type": "text"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ri_A9DjRDHbn",
    "colab_type": "text"
   },
   "source": [
    "Test the model on unseen data and log accuracy and F1 score to WandB."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f44Ak5gLQrFt",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "770039e6-cfc7-4ddc-ccc5-60f6005fdaea",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590986292226,
     "user_tz": -120,
     "elapsed": 18931260,
     "user": {
      "displayName": "Vasily Bochkarev",
      "photoUrl": "",
      "userId": "16683603869006222688"
     }
    }
   },
   "source": [
    "results = generic.evaluate(test_data_loader, **{'test_f1': f1_score, 'test_accuracy': accuracy_score})\n",
    "wandb.log(results)\n",
    "results"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.9139475367882278, 'test_f1': 0.8829677842334718}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 13
    }
   ]
  }
 ]
}